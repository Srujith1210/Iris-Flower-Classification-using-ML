ğŸŒ¸ Iris Flower Classification using Decision Tree

This project builds an end-to-end Machine Learning model to classify Iris flower species (Setosa, Versicolor, Virginica) based on sepal and petal measurements. The workflow includes data analysis, feature engineering, model training, pruning, visualization, and hyperparameter tuning.

ğŸš€ Project Overview

This project demonstrates:

Loading and exploring the Iris dataset

Feature engineering (adding petal & sepal area)

Training a Decision Tree Classifier

Pruning for better generalization

Visualizing the decision tree and decision boundaries

Hyperparameter tuning using GridSearchCV and RandomizedSearchCV

Evaluating performance using accuracy, F1 score, and confusion matrix

ğŸ§  Key Features

Feature Engineering: Created new columns like petal_area and sepal_area to improve model insights.

Pruned Decision Tree: Used max_depth and min_samples_leaf to reduce overfitting.

Visualizations:

Decision Tree structure

2D decision boundaries

Feature importance

Model Optimization:

GridSearchCV

RandomizedSearchCV

High Model Performance:

93% Test Accuracy

97% Cross-Validation F1 Macro Score

ğŸ“‚ Dataset

The dataset is the well-known Iris dataset, available in sklearn.datasets.
It contains 150 samples and 3 classes:

Setosa

Versicolor

Virginica

Features:

Sepal length

Sepal width

Petal length

Petal width

ğŸ› ï¸ Technologies Used

Python

NumPy

Pandas

Matplotlib

Seaborn

Scikit-learn

SciPy

ğŸ“˜ Project Workflow
1ï¸âƒ£ Load and explore data
2ï¸âƒ£ Create a DataFrame
3ï¸âƒ£ Feature Engineering
4ï¸âƒ£ Trainâ€“Test Split
5ï¸âƒ£ Baseline Decision Tree Model
6ï¸âƒ£ Pruned Decision Tree
7ï¸âƒ£ Visualizations
8ï¸âƒ£ Hyperparameter tuning
9ï¸âƒ£ Model evaluation
ğŸ“Š Model Performance
Metric	Score
Test Accuracy	93.33%
Test F1 Macro	93.26%
CV F1 Macro	97.47%

The model shows strong and stable performance without overfitting.

ğŸ“‰ Visualizations Included

Decision Tree plot

Decision boundaries (Petal Length vs Petal Width)

Feature importance chart

Pairplots for EDA

ğŸ§ª How to Run the Project
pip install numpy pandas matplotlib seaborn scikit-learn scipy


Run the Jupyter Notebook:

jupyter notebook

ğŸ“ Conclusion

This project highlights the power of Decision Trees for interpretable machine learning. With pruning, feature engineering, and hyperparameter tuning, the model achieves high accuracy while remaining easy to understand.
